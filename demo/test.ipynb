{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615f6a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "sys.path.append(\"../src\")  # Add the directory containing `src`\n",
    "from data_loader import DataLoader\n",
    "from schema_generator import SchemaGenerator\n",
    "from semantic_annotation import archetype_annotation\n",
    "from join_discoverer import JoinDiscoverer\n",
    "\n",
    "load_dotenv(\"/Users/matteocastagna/Documents/Università/Assegno di ricerca 2024:2025/SemLink/.env\") # Insert the path to your .env file\n",
    "\n",
    "openai_client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))  # Or use your actual API key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7708e371",
   "metadata": {},
   "source": [
    "<h1>Eurostat<h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5419b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/Users/matteocastagna/Documents/Università/Assegno di ricerca 2024:2025/SemLink/demo/eurostat/data\"\n",
    "metadata_dir = \"/Users/matteocastagna/Documents/Università/Assegno di ricerca 2024:2025/SemLink/demo/eurostat/data\"\n",
    "output_dir = \"/Users/matteocastagna/Documents/Università/Assegno di ricerca 2024:2025/SemLink/demo/eurostat/output\"\n",
    "\n",
    "# Initialization\n",
    "data_loader = DataLoader(openai_client=openai_client)\n",
    "schema_gen = SchemaGenerator(openai_client=openai_client)\n",
    "join_dis = JoinDiscoverer(openai_client=openai_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabb85b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "datalake = data_loader.load_and_describe_datalake(\n",
    "    data_directory=data_dir, # Directory with CSV or TSV\n",
    "    metadata_directory=metadata_dir, # Optional directory with matadata in json format\n",
    "    llm=True, # Produce a desciption with an LLM for each column\n",
    "    sample_size=10, # How many values sample from a column\n",
    "    output_directory=os.path.join(output_dir, \"datalake\") # Directory to save the output json\n",
    ")\n",
    "\n",
    "print(f\"\\nProcessed {len(datalake)} files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55baac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate LinkML schema\n",
    "schema = schema_gen.generate_linkml_schema(\n",
    "    data_lake_list = datalake, # Either the list of dict produced by load_and_describe_datalake or the path to the json file produced\n",
    "    output_directory=os.path.join(output_dir, \"schema\") # Directory to save the output yaml\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a831a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prune LinkML schema\n",
    "pruned_schema = schema_gen.prune_schema(\n",
    "    data_lake_list = datalake, # Either the list of dict produced by load_and_describe_datalake or the path to the json file produced\n",
    "    yaml_schema = schema, # Either the dict produced by generate_linkml_schema or path to the yaml file produced\n",
    "    output_directory=os.path.join(output_dir, \"schema\") # Directory to save the output yaml\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67dfdd39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Semnaitc column annotaiton with ArcheType\n",
    "datalake_annotated = archetype_annotation(\n",
    "    data_lake_list=datalake, # Either the list of dict produced by load_and_describe_datalake or the path to the json file produced\n",
    "    yaml_schema=pruned_schema,  # Either the dict produced by generate_linkml_schema/prune_schema or path to the yaml file produced\n",
    "    sample_size=10, # How many samples of the column pass to Archetype for the annotation\n",
    "    output_directory=os.path.join(output_dir, \"datalake\") # Directory to save the output json\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abaf56ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate embeddings for each column\n",
    "embeddings = join_dis.generate_embeddings(\n",
    "    data_lake_list=datalake_annotated, # Either the list of dict produced by load_and_describe_datalake/archetype_annotation or the path to the json file produced\n",
    "    output_directory=os.path.join(output_dir, \"embeddings\") # Directory to save the output json\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45cff4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Neo4j graph\n",
    "join_dis.compute_distances_and_export_neo4j(\n",
    "    embeddings=embeddings, # Either the list of dict produced by generate_embeddings or the path to the json file produced\n",
    "    cosine_sim_threshold = 0.5,\n",
    "    anns_threshold = 0.2,\n",
    "    output_directory=os.path.join(output_dir, \"neo4j\") # Directory to save the output CSVs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce8597a",
   "metadata": {},
   "source": [
    "<h1>PKT<h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316da7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/Users/matteocastagna/Documents/Università/Assegno di ricerca 2024:2025/SemLink/demo/pkt/data\"\n",
    "output_dir = \"/Users/matteocastagna/Documents/Università/Assegno di ricerca 2024:2025/SemLink/demo/pkt/output\"\n",
    "\n",
    "# Initialization\n",
    "data_loader = DataLoader(openai_client=openai_client)\n",
    "schema_gen = SchemaGenerator(openai_client=openai_client)\n",
    "join_dis = JoinDiscoverer(openai_client=openai_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eddcaf83",
   "metadata": {},
   "outputs": [],
   "source": [
    "datalake = data_loader.load_and_describe_datalake(\n",
    "    data_directory=data_dir, # Directory with CSV or TSV\n",
    "    llm=True, # Produce a desciption with an LLM for each column\n",
    "    sample_size=10, # How many values sample from a column\n",
    "    output_directory=os.path.join(output_dir, \"datalake\") # Directory to save the output json\n",
    ")\n",
    "\n",
    "print(f\"\\nProcessed {len(datalake)} files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac882a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate LinkML schema\n",
    "schema = schema_gen.generate_linkml_schema(\n",
    "    data_lake_list = datalake, # Either the list of dict produced by load_and_describe_datalake or the path to the json file produced\n",
    "    output_directory=os.path.join(output_dir, \"schema\") # Directory to save the output yaml\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891a4392",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prune LinkML schema\n",
    "pruned_schema = schema_gen.prune_schema(\n",
    "    data_lake_list = datalake, # Either the list of dict produced by load_and_describe_datalake or the path to the json file produced\n",
    "    yaml_schema = schema, # Either the dict produced by generate_linkml_schema or path to the yaml file produced\n",
    "    output_directory=os.path.join(output_dir, \"schema\") # Directory to save the output yaml\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e31519",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Semnaitc column annotaiton with ArcheType\n",
    "datalake_annotated = archetype_annotation(\n",
    "    data_lake_list=datalake, # Either the list of dict produced by load_and_describe_datalake or the path to the json file produced\n",
    "    yaml_schema=pruned_schema,  # Either the dict produced by generate_linkml_schema/prune_schema or path to the yaml file produced\n",
    "    sample_size=10, # How many samples of the column pass to Archetype for the annotation\n",
    "    output_directory=os.path.join(output_dir, \"datalake\") # Directory to save the output json\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99694b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate embeddings for each column\n",
    "embeddings = join_dis.generate_embeddings(\n",
    "    data_lake_list=datalake_annotated, # Either the list of dict produced by load_and_describe_datalake/archetype_annotation or the path to the json file produced\n",
    "    output_directory=os.path.join(output_dir, \"embeddings\") # Directory to save the output json\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1843f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Neo4j graph\n",
    "join_dis.compute_distances_and_export_neo4j(\n",
    "    embeddings=embeddings, # Either the list of dict produced by generate_embeddings or the path to the json file produced\n",
    "    cosine_sim_threshold = 0.5,\n",
    "    anns_threshold = 0.2,\n",
    "    output_directory=os.path.join(output_dir, \"neo4j\") # Directory to save the output CSVs\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "archetype2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
